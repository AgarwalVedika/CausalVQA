{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "import config\n",
    "import json\n",
    "import os\n",
    "import random\n",
    "import pickle\n",
    "random.seed(1234)\n",
    "import numpy as np; np.random.seed(1234)\n",
    "from utils_picking import my_read_old, round_percent, vqa_score_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "TEST_SPLIT = \"val2014\"\n",
    "\n",
    "MODEL = \"SNMN\"   # alternatively can put \"SAAA\", \"CNN_LSTM\" \n",
    "\n",
    "#note: for testing- we test on those IQAs from val where 10 answers are uniform"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_root_dir_qa = 'testing_iv_vqa/original'\n",
    "edit_root_dir_qa = 'testing_iv_vqa/edited'\n",
    "coco_json = 'coco_cat_ids.json'\n",
    "\n",
    "#### questions keys: 'image_id', 'question', 'question_id'\n",
    "res_file_q = 'v2_OpenEnded_mscoco_' + TEST_SPLIT + '_questions.json'\n",
    "standard_questions_val_json = os.path.join(orig_root_dir_qa, res_file_q)\n",
    "standard_questions_edit_val_json = os.path.join(edit_root_dir_qa, res_file_q)\n",
    "\n",
    "## ann keys: 'image_id', 'question_id', 'answers' , 'multiple_choice_answer'(the most frequent answer), 'question_type', 'answer_type'\n",
    "res_file_a = 'v2_mscoco_' + TEST_SPLIT + '_annotations.json'\n",
    "standard_annotations_val_json = os.path.join(orig_root_dir_qa, res_file_a)\n",
    "standard_annotations_edit_val_json = os.path.join(edit_root_dir_qa, res_file_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "### make changes here\n",
    "if MODEL == 'SNMN':\n",
    "    results_edit_val= config.results_edit_val_snmn\n",
    "    results_val= config.results_val_snmn\n",
    "    ## standard_vocab file_model_specific\n",
    "    standard_vocab_ans_file = config.standard_vocab_ans_file_snmn\n",
    "    with open(standard_vocab_ans_file) as f:\n",
    "        ans_vocab_list = f.read().splitlines()\n",
    "    \n",
    "elif MODEL == 'SAAA':\n",
    "    results_edit_val = config.results_edit_val_saaa\n",
    "    results_val = config.results_val_saaa\n",
    "    ## standard_vocab file_model_specific\n",
    "    vocab = config.standard_vocab_ans_file_saaa\n",
    "    with open(vocab, 'r') as f:\n",
    "        ans_vocab = json.load(f)[\"answer\"]\n",
    "        ans_vocab_list = [k for k, v in ans_vocab.items()]\n",
    "        #{v: k for k, v in ans_vocab.items()}   ### is a dictionary here but will work: keys- index- 0,1,2...\n",
    "\n",
    "elif MODEL == 'CNN_LSTM':\n",
    "    results_edit_val = config.results_edit_val_cnn_lstm\n",
    "    results_val = config.results_val_cnn_lstm\n",
    "    ## standard_vocab file_model_specific\n",
    "    vocab = config.standard_vocab_ans_file_cnn_lstm\n",
    "    with open(vocab, 'r') as f:\n",
    "        ans_vocab = json.load(f)[\"answer\"]\n",
    "        ans_vocab_list = [k for k, v in ans_vocab.items()]\n",
    "        # {v: k for k, v in ans_vocab.items()}   ### is a dictionary here but will work: keys- index- 0,1,2...\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.4199817180633545\n"
     ]
    }
   ],
   "source": [
    "qid_val, pred_ans_val , ss_vc_val, img_ids_val, ques_val, all_ans_val, ques_type_val, ans_type_val = my_read_old(results_val, standard_questions_val_json, standard_annotations_val_json)\n",
    "\n",
    "qid_edit_val, pred_ans_edit_val , ss_vc_edit_val, img_ids_edit_val, ques_edit_val, all_ans_edit_val, ques_type_edit_val, ans_type_edit_val = my_read_old(results_edit_val, standard_questions_edit_val_json, standard_annotations_edit_val_json)\n",
    "\n",
    "masking_indices_where_qid_edit_but_no_orig_qid = [idx for idx, i in enumerate(qid_edit_val) if i not in qid_val]\n",
    "stop_idx = masking_indices_where_qid_edit_but_no_orig_qid[0]\n",
    "qid_edit_val = qid_edit_val[0:stop_idx]\n",
    "qid_edit_val, pred_ans_edit_val, ss_vc_edit_val, img_ids_edit_val, ques_edit_val, all_ans_edit_val, ques_type_edit_val, ans_type_edit_val = [\n",
    "    i[0:stop_idx] for i in\n",
    "    [qid_edit_val, pred_ans_edit_val, ss_vc_edit_val, img_ids_edit_val, ques_edit_val, all_ans_edit_val,\n",
    "     ques_type_edit_val, ans_type_edit_val]]\n",
    "print(stop_idx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size of original set: 63219\n",
      "size of edited set: 108239\n",
      "no of unique images in val_set:  29376\n",
      "no of unique images in edit_val_set:  53855\n",
      "#unique questions in original set:  63219\n",
      "#unique questions in edited set:  45076\n",
      "not every question in orig_val made it to edit_val=> for  18143  questions- no legit edited IQA possible\n"
     ]
    }
   ],
   "source": [
    "len_val = len(img_ids_val)\n",
    "len_edit_val = len(img_ids_edit_val)\n",
    "all_indices_val = np.arange(len_val)\n",
    "all_indices_edit_val = np.arange(len_edit_val)\n",
    "\n",
    "print('size of original set:', len_val)\n",
    "print('size of edited set:', len_edit_val)\n",
    "print('no of unique images in val_set: ',len(set(img_ids_val)))\n",
    "print('no of unique images in edit_val_set: ',len(set(img_ids_edit_val)))\n",
    "print('#unique questions in original set: ',len(list(set(qid_val))) )\n",
    "print('#unique questions in edited set: ', len(list(set(qid_edit_val))))\n",
    "    \n",
    "if len(list(set(qid_val))) != len(list(set(qid_edit_val))) :\n",
    "    print('not every question in orig_val made it to edit_val=> for ', len(list(set(qid_val)))- len(list(set(qid_edit_val)))  ,' questions- no legit edited IQA possible')\n",
    "\n",
    "qid_gt_ans_label = {}\n",
    "for idx,a in enumerate(qid_val):\n",
    "    qid_gt_ans_label[a] = all_ans_val[idx]\n",
    "    \n",
    "qid_predans_val = {}\n",
    "for idx, a in enumerate(qid_val):\n",
    "    qid_predans_val.setdefault(a, []).append(pred_ans_val[idx])\n",
    "    \n",
    "qid_predans_idx_val = {}\n",
    "for idx, a in enumerate(qid_val):\n",
    "    qid_predans_idx_val.setdefault(a, []).append(idx)\n",
    "    \n",
    "#idx in case here refers to len(val and edit_val- order hai - so relax)    \n",
    "qid_predans_edit_val = {}\n",
    "for idx, a in enumerate(qid_edit_val):\n",
    "    qid_predans_edit_val.setdefault(a, []).append(pred_ans_edit_val[idx])\n",
    "    #qid_predans_edit_val[a] = (pred_ans_edit_val[idx])   \n",
    "    \n",
    "qid_predans_idx_edit_val = {}\n",
    "for idx, a in enumerate(qid_edit_val):\n",
    "    qid_predans_idx_edit_val.setdefault(a, []).append(idx)    \n",
    "    \n",
    "# qid_predans_imgid_edit_val = {}\n",
    "# for idx, a in enumerate(qid_edit_val):\n",
    "#     qid_predans_imgid_edit_val.setdefault(a, []).append(img_ids_edit_val[idx])   \n",
    "\n",
    "## creating dictionary for val set - to facilitate extensions based on q_id index\n",
    "qid_ss_predans_val = {}\n",
    "for idx, a in enumerate(qid_val):\n",
    "    qid_ss_predans_val[a] = (ss_vc_val[idx], pred_ans_val[idx], qid_val[idx],idx, all_ans_val[idx])\n",
    "\n",
    "extended_ss_vc_val = [qid_ss_predans_val[q_id][0] for q_id in qid_edit_val]\n",
    "extended_pred_ans_val = [qid_ss_predans_val[q_id][1] for q_id in qid_edit_val] \n",
    "#extended_qid_val = [qid_ss_predans_val[q_id][2] for q_id in qid_edit_val]\n",
    "\n",
    "collapsed_pred_ans_val = [qid_ss_predans_val[q_id][1] for q_id in set(qid_edit_val)] \n",
    "collapsed_all_ans_val = [qid_ss_predans_val[q_id][4] for q_id in set(qid_edit_val)] \n",
    "collapsed_indices = [qid_ss_predans_val[q_id][3] for q_id in set(qid_edit_val)] \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy before editing, one answer match is good 66.039 41749\n",
      "accuracy before editing_10_ans_same, one answer match is good 66.039 63219\n",
      "accuracy before editing_extended 65.447 70839\n",
      "accuracy after editing, one answer match is good 65.146 70513\n",
      "accuracy before editing_collapsed 65.671\n",
      "worst case accuracy (45076):  63.178\n",
      "best case accuracy (45076):  67.517\n",
      "worst case official accuracy (45076):  63.178\n",
      "best case official accuracy (45076):  67.517\n",
      "official accuracy before editing 66.039\n",
      "official accuracy before editing_all_10_ans_same 66.039 63219\n",
      "official accuracy before editing_extended 65.447\n",
      "official accuracy after editing 65.146\n",
      "official accuracy before editing_collapsed 65.671\n"
     ]
    }
   ],
   "source": [
    "###                                         STATISTICS\n",
    "assert len(collapsed_indices) == len(set(qid_edit_val))\n",
    "ind_where_10_ans_same = [idx for idx, i in enumerate(all_ans_val) if len(set(i))==1 ]  \n",
    "accuracy_ind_bf_10_ans_same = [i for i in ind_where_10_ans_same if ans_vocab_list[pred_ans_val[i]] in all_ans_val[i]]\n",
    "\n",
    "##official_way\n",
    "off_score_val = vqa_score_list(all_ans_val, pred_ans_val, ans_vocab_list)\n",
    "off_score_val_extended = vqa_score_list(all_ans_edit_val, extended_pred_ans_val, ans_vocab_list)\n",
    "off_score_val_collapsed = vqa_score_list(collapsed_all_ans_val, collapsed_pred_ans_val, ans_vocab_list)\n",
    "off_score_edit_val = vqa_score_list(all_ans_edit_val, pred_ans_edit_val, ans_vocab_list)\n",
    "print('official accuracy before editing', round_percent(np.sum(off_score_val) / len_val))\n",
    "print('official accuracy before editing_all_10_ans_same', round_percent(len(accuracy_ind_bf_10_ans_same) / len(ind_where_10_ans_same)), len(ind_where_10_ans_same))\n",
    "print('official accuracy before editing_extended', round_percent(np.sum(off_score_val_extended) / len_edit_val))\n",
    "print('official accuracy after editing', round_percent(np.sum(off_score_edit_val) / len_edit_val))\n",
    "print('official accuracy before editing_collapsed', round_percent(np.sum(off_score_val_collapsed) / len(collapsed_indices)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#labels flipped for entire set= 7059        6.522 %\n",
      "#labels remained same= 101180         93.478 %\n",
      "#labels flipped that show a positive change 2758           2.548 %\n",
      "#labels flipped that show a negative change 3084           2.849 %\n",
      "#labels flipped that are both right 0           0.0 %\n",
      "#labels flipped that are both wrong 1217           1.124 %\n",
      "#labels same that are both right 67755           62.598 %\n",
      "#labels same that are both wrong 33425           30.881 %\n"
     ]
    }
   ],
   "source": [
    "### for entire set counting how mnay labels flipped\n",
    "labels_flipped_count = np.sum([extended_pred_ans_val[i] != val for i, val in enumerate(pred_ans_edit_val)])\n",
    "labels_remained_same_count = np.sum([extended_pred_ans_val[i] == val for i, val in enumerate(pred_ans_edit_val)])\n",
    "assert (labels_flipped_count + labels_remained_same_count == len(pred_ans_edit_val))\n",
    "print('#labels flipped for entire set=', labels_flipped_count,'      ' ,\n",
    "      round_percent(labels_flipped_count / len_edit_val), '%')\n",
    "      \n",
    "print('#labels remained same=', labels_remained_same_count,'       ', \n",
    "      round_percent(labels_remained_same_count / len_edit_val), '%')\n",
    "\n",
    "lab_fl_ind = [i for i in range(len_edit_val) if extended_pred_ans_val[i] != pred_ans_edit_val[i]]\n",
    "# label i.e ans was wrong before- right now- one match to 10gt ans is okay\n",
    "lab_fl_pos = [i for i in lab_fl_ind if ans_vocab_list[extended_pred_ans_val[i]] not in all_ans_edit_val[i] and ans_vocab_list[pred_ans_edit_val[i]] in all_ans_edit_val[i]]\n",
    "# label i.e ans was right before- now wrong - one match to 10gt ans is okay\n",
    "lab_fl_neg = [i for i in lab_fl_ind if ans_vocab_list[extended_pred_ans_val[i]] in all_ans_edit_val[i] and ans_vocab_list[pred_ans_edit_val[i]] not in all_ans_edit_val[i]]\n",
    "lab_fl_right = [i for i in lab_fl_ind if ans_vocab_list[extended_pred_ans_val[i]] in all_ans_edit_val[i] and ans_vocab_list[pred_ans_edit_val[i]] in all_ans_edit_val[i]]\n",
    "lab_fl_wrong = [i for i in lab_fl_ind if ans_vocab_list[extended_pred_ans_val[i]] not in all_ans_edit_val[i] and ans_vocab_list[pred_ans_edit_val[i]] not in all_ans_edit_val[i]]\n",
    "print('#labels flipped that show a positive change', len(lab_fl_pos), '         ', \n",
    "      round_percent(len(lab_fl_pos) / len_edit_val), '%' )\n",
    "print('#labels flipped that show a negative change', len(lab_fl_neg), '         ', \n",
    "      round_percent(len(lab_fl_neg) / len_edit_val), '%')\n",
    "print('#labels flipped that are both right', len(lab_fl_right), '         ', round_percent(len(lab_fl_right) / len_edit_val), '%')\n",
    "print('#labels flipped that are both wrong', len(lab_fl_wrong), '         ', round_percent(len(lab_fl_wrong) / len_edit_val), '%')\n",
    "assert(len(lab_fl_pos) + len(lab_fl_neg) + len(lab_fl_right) + len(lab_fl_wrong) == len(lab_fl_ind))\n",
    "\n",
    "\n",
    "lab_sm_ind = [i for i in range(len_edit_val) if extended_pred_ans_val[i] == pred_ans_edit_val[i]]\n",
    "# labels that remained exactly same- so two cases possible- either right/wrong\n",
    "lab_sm_right = [i for i in lab_sm_ind if ans_vocab_list[pred_ans_edit_val[i]] in all_ans_edit_val[i]]\n",
    "lab_sm_wrong = [i for i in lab_sm_ind if ans_vocab_list[pred_ans_edit_val[i]] not in all_ans_edit_val[i]]\n",
    "print('#labels same that are both right', len(lab_sm_right), '         ', round_percent(len(lab_sm_right)/len_edit_val), '%')\n",
    "print('#labels same that are both wrong', len(lab_sm_wrong), '         ', round_percent(len(lab_sm_wrong) / len_edit_val), '%')\n",
    "assert (len(lab_sm_right) + len(lab_sm_wrong) == len(lab_sm_ind))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}