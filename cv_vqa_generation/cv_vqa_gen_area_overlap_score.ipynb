{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import time\n",
    "import itertools\n",
    "from torch.utils.data import Dataset\n",
    "import ipdb\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pickle\n",
    "from pycocotools.coco import COCO\n",
    "from skimage.morphology import disk, square\n",
    "from collections import defaultdict\n",
    "import scipy\n",
    "import config\n",
    "selem = disk(2)\n",
    "square_dil = square(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "cosider_flip_too = 0\n",
    "all_10_ans_common=1\n",
    "\n",
    "coco_val_pkl = './../iv_vqa_generation/coco_areas_and_intersection/coco_vqa_val2014.json'\n",
    "coco_train_pkl = './../iv_vqa_generation/coco_areas_and_intersection/coco_vqa_train2014.json'\n",
    "\n",
    "COCO_val = COCO(config.coco_ann_dir + 'instances_val2014.json')\n",
    "COCO_train = COCO(config.coco_ann_dir + 'instances_train2014.json')\n",
    "ann_coco_file_val = config.coco_ann_dir + 'instances_val2014.json'\n",
    "ann_coco_file_train = config.coco_ann_dir + 'instances_train2014.json'\n",
    "with open(ann_coco_file_val) as f:\n",
    "    ann_coco_1 = json.load(f)['categories']\n",
    "coco_dict = {}\n",
    "for i, det in enumerate(ann_coco_1):\n",
    "    coco_dict[det['id']] = det['name']\n",
    "    \n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VQADataset_custom(Dataset):\n",
    "    \"\"\"VQA dataset\"\"\"\n",
    "\n",
    "    def __init__(self, coco_pkl_file, ques_ann_path, ans_ann_path, mode):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            ques_ann (string): Path to the json file with ques_annotations.\n",
    "            ans_ann (string): Path to the json file with ans_annotations.\n",
    "        \"\"\"\n",
    "        self.coco_details = pickle.load(open(coco_pkl_file, 'rb'))['area_and_intersection']        \n",
    "        self.questions = json.load(open(ques_ann_path, 'r'))['questions']  ###or self.questions = load_vocab(ques_ann_path)\n",
    "        self.answers = json.load(open(ans_ann_path, 'r'))['answers']\n",
    "        self.mode = mode\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.questions)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"Returns ONE data pair-image,match_coco_objects\"\"\"\n",
    "        \n",
    "        q = self.questions\n",
    "        area_inter = self.coco_details\n",
    "        ans = self.answers\n",
    "        \n",
    "        assert q[idx]['image_id'] == area_inter[idx]['image_id'] == ans[idx]['image_id']\n",
    "        \n",
    "        \n",
    "        classes_img = area_inter[idx]['classes_img']\n",
    "        percent_area_per_catId_all_inst = area_inter[idx]['percent_area_per_catId_all_inst']\n",
    "        percent_area_per_catId_max_inst = area_inter[idx]['percent_area_per_catId_max_inst']\n",
    "        if_intersect_overlap_sq5 = area_inter[idx]['if_intersect_overlap_sq5'] # or \"if_intersect_overlap_default\"\n",
    "        #if_intersect_overlap_default = area_inter[idx]['if_intersect_overlap_default']\n",
    "        flipped_if_intersect_overlap_sq5 = area_inter[idx]['flipped_if_intersect_overlap_sq5']\n",
    "        iou_mask_flipped_mask = area_inter[idx]['iou_mask_flipped_mask']\n",
    "        \n",
    "        # print('Reading image data')\n",
    "        img_id = self.questions[idx]['image_id']\n",
    "        # print(img_id)\n",
    "\n",
    "        question = self.questions[idx]['question']\n",
    "        question_id = self.questions[idx]['question_id']\n",
    "        # nouns_q = questions[idx]['nouns_q']\n",
    "        # nouns_q_coco_stuff = questions[idx]['nouns_q_COCO_stuff']\n",
    "\n",
    "        # print('Reading nouns data')\n",
    "        nouns_q_coco = self.questions[idx]['nouns_q_COCO']\n",
    "        nouns_ans = self.answers[idx]['ans_match_COCO']\n",
    "        # print(img_id, nouns_img, nouns_q_coco, nouns_ans )\n",
    "        \n",
    "        answers = [i['answer'] for i in self.answers[idx]['answers']]\n",
    "        \n",
    "        question_type = self.answers[idx]['question_type']\n",
    "        #multipe_choice_answer = self.answers[idx]['multipe_choice_answer']\n",
    "        question_id2 = self.answers[idx]['question_id']\n",
    "        assert question_id==question_id2\n",
    "        \n",
    "        answer_type = self.answers[idx]['answer_type']\n",
    "        \n",
    "        if cosider_flip_too:\n",
    "            return answers, classes_img, nouns_q_coco, nouns_ans, img_id, question_id, question, \\\n",
    "                percent_area_per_catId_all_inst,if_intersect_overlap_sq5, percent_area_per_catId_max_inst,\\\n",
    "                flipped_if_intersect_overlap_sq5, iou_mask_flipped_mask, question_type, answer_type\n",
    "        else:\n",
    "            return answers, classes_img, nouns_q_coco, nouns_ans, img_id, question_id, question, \\\n",
    "                percent_area_per_catId_all_inst,if_intersect_overlap_sq5, percent_area_per_catId_max_inst, \\\n",
    "                question_type, answer_type\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_dict(given_list):\n",
    "    nouns_dict = {}\n",
    "    for i in given_list:\n",
    "        if i in nouns_dict:\n",
    "            nouns_dict[i]+=1\n",
    "        else:\n",
    "            nouns_dict[i] =1\n",
    "    return nouns_dict\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "mode = \"train2014\"   \n",
    "coco = COCO_train\n",
    "images_json_path ='coco_classes_' + mode + '_images.json'         #### contains img ids and classes in each image\n",
    "question_path = './../iv_vqa_generation/tagged_' + mode + '_questions.json'        ## corresponds to question.json file\n",
    "answer_path = './../iv_vqa_generation/tagged_'  + mode + '_answers.json'        \n",
    "start = time.time()\n",
    "dataset= VQADataset_custom(coco_train_pkl, question_path, answer_path, mode)\n",
    "\n",
    "###GENERATING JSON FILE FOR COCO IMAGES!!\n",
    "count_data_human_supervision = []\n",
    "id_area_overlap = []\n",
    "count=0\n",
    "number_of_objects =0\n",
    "allowed_char_in_ans = [str(i) for i in range(10)] #['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n",
    "\n",
    "for i in range(len(dataset)):#range(len(dataset)):\n",
    "    if cosider_flip_too:\n",
    "        answers, classes_img, nouns_q, nouns_ans, img_id, ques_id, question,\\\n",
    "        percent_area_per_catId_all_inst,if_intersect_overlap, percent_area_per_catId_max_inst, \\\n",
    "        flipped_if_intersect_overlap_sq5, iou_mask_flipped_mask, question_type, answer_type = dataset[i]\n",
    "    else:\n",
    "        answers, classes_img, nouns_q, nouns_ans, img_id, ques_id, question,\\\n",
    "        percent_area_per_catId_all_inst,if_intersect_overlap, percent_area_per_catId_max_inst, \\\n",
    "        question_type, answer_type = dataset[i]     \n",
    "\n",
    "    classes_img_set = sorted(list(set(classes_img)))\n",
    "\n",
    "    nouns_q_str = [coco_dict[i] for i in nouns_q]\n",
    "    classes_img_str = [coco_dict[i] for i in classes_img]\n",
    "\n",
    "    count_nouns_q = count_dict(nouns_q)\n",
    "    count_classes_img = count_dict(classes_img)\n",
    "\n",
    "    ans_cond = [True if i in allowed_char_in_ans else False for i in answers[0]]\n",
    "    final_ans_cond = True\n",
    "    if False in ans_cond:\n",
    "        final_ans_cond = False\n",
    "    #ques_condition_neg ='number of' not in question and 'many' not in question and 'what number is' not in question\\\n",
    "    #and \"What's the number\" not in question and  'What number is' not in question\n",
    "    if 'many' in question:\n",
    "        if 'person' in count_nouns_q.keys():\n",
    "            count_nouns_q['person']= count_nouns_q['person']-1\n",
    "            if count_nouns_q['person']==0:\n",
    "                del count_nouns_q['person']\n",
    "        elif 1 in count_nouns_q.keys():\n",
    "            count_nouns_q[1]= count_nouns_q[1]-1\n",
    "            if count_nouns_q[1]==0:\n",
    "                del count_nouns_q[1]\n",
    "\n",
    "    ques_condition= 'many' in question or 'number of' in question \n",
    "    if len(set(answers))==1 and answer_type =='number' and final_ans_cond and ques_condition:\n",
    "\n",
    "        ideal_candidates = []\n",
    "        final_candi = []\n",
    "\n",
    "        for key in count_classes_img:\n",
    "            if key in count_nouns_q:\n",
    "                ideal_candidates.append(key)\n",
    "        for key in ideal_candidates: #count_classes_img:\n",
    "            if count_classes_img[key]==int(answers[0]):\n",
    "                final_candi.append(key)\n",
    "        if len(final_candi)==1:\n",
    "            count += 1\n",
    "            cat_id = final_candi[0]\n",
    "            num_obj_rem = int(answers[0])\n",
    "            area_img = coco.imgs[img_id]['height'] * coco.imgs[img_id]['width']\n",
    "            all_possible_ann = coco.loadAnns(coco.getAnnIds(img_id, cat_id))\n",
    "            \n",
    "            for ann in all_possible_ann:\n",
    "                mini_dict = {}\n",
    "                mini_dict['id'] = ann['id']\n",
    "                area_occupied = round((ann['area']/area_img),3)\n",
    "                mini_dict['area_occupied'] = area_occupied\n",
    "                mini_dict['image_id'] = img_id\n",
    "                mini_dict['question_id']= ques_id\n",
    "                \n",
    "                overlap_score = 0\n",
    "        \n",
    "                if area_occupied < 0.1:         \n",
    "                    \n",
    "                    mask_instance = coco.annToMask(ann)\n",
    "                    mask_instance_dilated = scipy.ndimage.morphology.binary_dilation(mask_instance, square_dil)\n",
    "                    all_possible_ann_mutable = coco.loadAnns(coco.getAnnIds(img_id, cat_id))\n",
    "                    ann_index_in_all_possible_ann = all_possible_ann.index(ann)                \n",
    "                    #print(all_possible_ann)\n",
    "                    #print(all_possible_ann_mutable)\n",
    "                    del all_possible_ann_mutable[ann_index_in_all_possible_ann]\n",
    "                    #print(all_possible_ann)\n",
    "                    #print(all_possible_ann_mutable)\n",
    "\n",
    "                    if len(all_possible_ann_mutable) >0:      \n",
    "                        maskTotal = np.zeros((coco.imgs[img_id]['height'], coco.imgs[img_id]['width']))\n",
    "\n",
    "                        for ann2 in all_possible_ann_mutable:\n",
    "                            cm = coco.annToMask(ann2)\n",
    "                            maskTotal[:cm.shape[0], :cm.shape[1]] += cm                                 \n",
    "                        maskTotal_dilated = scipy.ndimage.morphology.binary_dilation(maskTotal, square_dil)  \n",
    "\n",
    "                        #print(img_id)\n",
    "                        #plt.imshow(mask_instance_dilated, cmap='gray', interpolation='nearest'); plt.show()\n",
    "                        #plt.imshow(maskTotal_dilated, cmap='gray', interpolation='nearest'); plt.show()\n",
    "\n",
    "                        overlap_score = round(np.sum(mask_instance_dilated * maskTotal_dilated) / (np.sum(maskTotal_dilated)),3)\n",
    "\n",
    "                        mini_dict['overlap_score_with_rest'] = overlap_score\n",
    "                        id_area_overlap.append(mini_dict)  \n",
    "                    else:\n",
    "                        mini_dict['overlap_score_with_rest'] = 'only_candidate_instance'\n",
    "                        \n",
    "                else:\n",
    "                    mini_dict['overlap_score_with_rest'] = 'area_instance >10%'                     \n",
    "                id_area_overlap.append(mini_dict)                    \n",
    "                #print(mini_dict)\n",
    "\n",
    "with open(mode + 'coco_counting_id_area_overlap_only_one_considered_at_a_time.pickle', 'wb') as f:  \n",
    "    pickle.dump(id_area_overlap,f,pickle.HIGHEST_PROTOCOL)\n",
    "print('done')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "with open(mode+ 'coco_counting_id_area_overlap_only_one_considered_at_a_time.pickle', 'rb') as file:\n",
    "    id_area_overlap = pickle.load(file)\n",
    "instance_ids_target = []\n",
    "all_imgs_counting = []\n",
    "target_count = 0\n",
    "for mini_details in id_area_overlap:\n",
    "    all_imgs_counting.append(mini_details['image_id'])\n",
    "    overlap_score = mini_details['overlap_score_with_rest']\n",
    "    if isinstance(overlap_score, float) or overlap_score == 'only_candidate_instance':\n",
    "        if isinstance(overlap_score, float) and overlap_score<=0.0:\n",
    "            #print(mini_details)\n",
    "            target_count +=1\n",
    "            instance_ids_target.append(mini_details['id'])\n",
    "        else:\n",
    "            target_count +=1\n",
    "            instance_ids_target.append(mini_details['id'])            \n",
    "print('so new edited #IQA:', target_count) \n",
    "print('unique images in counting edited set:', len(set(instance_ids_target)))\n",
    "print('#counting IQA in original set:', len(id_area_overlap))\n",
    "print('unique images in counting original set:', len(set(all_imgs_counting)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Repeating for val2014 set\n",
    "\n",
    "mode = \"val2014\"   \n",
    "coco = COCO_val\n",
    "images_json_path ='coco_classes_' + mode + '_images.json'         #### contains img ids and classes in each image\n",
    "question_path = './../iv_vqa_generation/tagged_' + mode + '_questions.json'        ## corresponds to question.json file\n",
    "answer_path = './../iv_vqa_generation/tagged_'  + mode + '_answers.json'        \n",
    "start = time.time()\n",
    "dataset= VQADataset_custom(coco_val_pkl, question_path, answer_path, mode)\n",
    "\n",
    "###GENERATING JSON FILE FOR COCO IMAGES!!\n",
    "count_data_human_supervision = []\n",
    "id_area_overlap = []\n",
    "count=0\n",
    "number_of_objects =0\n",
    "allowed_char_in_ans = [str(i) for i in range(10)] #['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n",
    "\n",
    "for i in range(len(dataset)):#range(len(dataset)):\n",
    "    if cosider_flip_too:\n",
    "        answers, classes_img, nouns_q, nouns_ans, img_id, ques_id, question,\\\n",
    "        percent_area_per_catId_all_inst,if_intersect_overlap, percent_area_per_catId_max_inst, \\\n",
    "        flipped_if_intersect_overlap_sq5, iou_mask_flipped_mask, question_type, answer_type = dataset[i]\n",
    "    else:\n",
    "        answers, classes_img, nouns_q, nouns_ans, img_id, ques_id, question,\\\n",
    "        percent_area_per_catId_all_inst,if_intersect_overlap, percent_area_per_catId_max_inst, \\\n",
    "        question_type, answer_type = dataset[i]     \n",
    "\n",
    "    classes_img_set = sorted(list(set(classes_img)))\n",
    "\n",
    "    nouns_q_str = [coco_dict[i] for i in nouns_q]\n",
    "    classes_img_str = [coco_dict[i] for i in classes_img]\n",
    "\n",
    "    count_nouns_q = count_dict(nouns_q)\n",
    "    count_classes_img = count_dict(classes_img)\n",
    "\n",
    "    ans_cond = [True if i in allowed_char_in_ans else False for i in answers[0]]\n",
    "    final_ans_cond = True\n",
    "    if False in ans_cond:\n",
    "        final_ans_cond = False\n",
    "    #ques_condition_neg ='number of' not in question and 'many' not in question and 'what number is' not in question\\\n",
    "    #and \"What's the number\" not in question and  'What number is' not in question\n",
    "    if 'many' in question:\n",
    "        if 'person' in count_nouns_q.keys():\n",
    "            count_nouns_q['person']= count_nouns_q['person']-1\n",
    "            if count_nouns_q['person']==0:\n",
    "                del count_nouns_q['person']\n",
    "        elif 1 in count_nouns_q.keys():\n",
    "            count_nouns_q[1]= count_nouns_q[1]-1\n",
    "            if count_nouns_q[1]==0:\n",
    "                del count_nouns_q[1]\n",
    "\n",
    "    ques_condition= 'many' in question or 'number of' in question \n",
    "    if len(set(answers))==1 and answer_type =='number' and final_ans_cond and ques_condition:\n",
    "\n",
    "        ideal_candidates = []\n",
    "        final_candi = []\n",
    "\n",
    "        for key in count_classes_img:\n",
    "            if key in count_nouns_q:\n",
    "                ideal_candidates.append(key)\n",
    "        for key in ideal_candidates: #count_classes_img:\n",
    "            if count_classes_img[key]==int(answers[0]):\n",
    "                final_candi.append(key)\n",
    "        if len(final_candi)==1:\n",
    "            count += 1\n",
    "            cat_id = final_candi[0]\n",
    "            num_obj_rem = int(answers[0])\n",
    "            area_img = coco.imgs[img_id]['height'] * coco.imgs[img_id]['width']\n",
    "            all_possible_ann = coco.loadAnns(coco.getAnnIds(img_id, cat_id))\n",
    "            \n",
    "            for ann in all_possible_ann:\n",
    "                mini_dict = {}\n",
    "                mini_dict['id'] = ann['id']\n",
    "                area_occupied = round((ann['area']/area_img),3)\n",
    "                mini_dict['area_occupied'] = area_occupied\n",
    "                mini_dict['image_id'] = img_id\n",
    "                mini_dict['question_id']= ques_id\n",
    "                \n",
    "                overlap_score = 0\n",
    "        \n",
    "                if area_occupied < 0.1:         \n",
    "                    \n",
    "                    mask_instance = coco.annToMask(ann)\n",
    "                    mask_instance_dilated = scipy.ndimage.morphology.binary_dilation(mask_instance, square_dil)\n",
    "                    all_possible_ann_mutable = coco.loadAnns(coco.getAnnIds(img_id, cat_id))\n",
    "                    ann_index_in_all_possible_ann = all_possible_ann.index(ann)                \n",
    "                    #print(all_possible_ann)\n",
    "                    #print(all_possible_ann_mutable)\n",
    "                    del all_possible_ann_mutable[ann_index_in_all_possible_ann]\n",
    "                    #print(all_possible_ann)\n",
    "                    #print(all_possible_ann_mutable)\n",
    "\n",
    "                    if len(all_possible_ann_mutable) >0:      \n",
    "                        maskTotal = np.zeros((coco.imgs[img_id]['height'], coco.imgs[img_id]['width']))\n",
    "\n",
    "                        for ann2 in all_possible_ann_mutable:\n",
    "                            cm = coco.annToMask(ann2)\n",
    "                            maskTotal[:cm.shape[0], :cm.shape[1]] += cm                                 \n",
    "                        maskTotal_dilated = scipy.ndimage.morphology.binary_dilation(maskTotal, square_dil)  \n",
    "\n",
    "                        #print(img_id)\n",
    "                        #plt.imshow(mask_instance_dilated, cmap='gray', interpolation='nearest'); plt.show()\n",
    "                        #plt.imshow(maskTotal_dilated, cmap='gray', interpolation='nearest'); plt.show()\n",
    "\n",
    "                        overlap_score = round(np.sum(mask_instance_dilated * maskTotal_dilated) / (np.sum(maskTotal_dilated)),3)\n",
    "\n",
    "                        mini_dict['overlap_score_with_rest'] = overlap_score\n",
    "                        id_area_overlap.append(mini_dict)  \n",
    "                    else:\n",
    "                        mini_dict['overlap_score_with_rest'] = 'only_candidate_instance'\n",
    "                        \n",
    "                else:\n",
    "                    mini_dict['overlap_score_with_rest'] = 'area_instance >10%'                     \n",
    "                id_area_overlap.append(mini_dict)                    \n",
    "                #print(mini_dict)\n",
    "\n",
    "with open(mode + 'coco_counting_id_area_overlap_only_one_considered_at_a_time.pickle', 'wb') as f:  \n",
    "    pickle.dump(id_area_overlap,f,pickle.HIGHEST_PROTOCOL)\n",
    "print('done')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}