{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import time\n",
    "from torch.utils.data import Dataset\n",
    "import pickle\n",
    "import config\n",
    "import ipdb\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "class VQADataset_custom_ans(Dataset):\n",
    "    \"\"\"VQA dataset\"\"\"\n",
    "\n",
    "    def __init__(self, coco_pkl_file, ques_ann_path, ans_ann_path, mode):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            ques_ann (string): Path to the json file with ques_annotations.\n",
    "            ans_ann (string): Path to the json file with ans_annotations.\n",
    "        \"\"\"\n",
    "        \n",
    "        self.coco_details = pickle.load(open(coco_pkl_file, 'rb'))['area_and_intersection']        \n",
    "        self.questions = json.load(open(ques_ann_path, 'r'))['questions']  ###or self.questions = load_vocab(ques_ann_path)\n",
    "        self.answers = json.load(open(ans_ann_path, 'r'))['answers']\n",
    "        self.mode = mode\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.answers)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"Returns ONE data pair-image,match_coco_objects\"\"\"\n",
    "        \n",
    "        q = self.questions\n",
    "        area_inter = self.coco_details\n",
    "        ans = self.answers\n",
    "        \n",
    "        assert q[idx]['image_id'] == area_inter[idx]['image_id'] == ans[idx]['image_id']\n",
    "         \n",
    "        classes_img = area_inter[idx]['classes_img']\n",
    "        percent_area_per_catId_all_inst = area_inter[idx]['percent_area_per_catId_all_inst']\n",
    "        percent_area_per_catId_max_inst = area_inter[idx]['percent_area_per_catId_max_inst']\n",
    "        if_intersect_overlap_sq5 = area_inter[idx]['if_intersect_overlap_sq5'] #\"if_intersect_overlap_default\"\n",
    "        #if_intersect_overlap_default = area_inter[idx]['if_intersect_overlap_default']\n",
    "        \n",
    "        # print('Reading image data')\n",
    "        img_id = self.answers[idx]['image_id']  ####sanity check: should conincide with self.image_ids[idx]- done - same!\n",
    "        # print(img_id)\n",
    "\n",
    "        question_type = self.answers[idx]['question_type']\n",
    "        multipe_choice_answer = self.answers[idx]['multipe_choice_answer']\n",
    "        answers = self.answers[idx]['answers']\n",
    "        question_id = self.answers[idx]['question_id']\n",
    "        answer_type = self.answers[idx]['answer_type']\n",
    "\n",
    "        # print('Reading nouns data')\n",
    "        nouns_q_coco = self.questions[idx]['nouns_q_COCO']\n",
    "        nouns_ans = self.answers[idx]['ans_match_COCO']\n",
    "        # print(img_id, nouns_img, nouns_q_coco, nouns_ans )\n",
    "        \n",
    "        ans10 = [i['answer'] for i in self.answers[idx]['answers']]\n",
    "        \n",
    "        return ans10, classes_img, nouns_q_coco, nouns_ans, question_type, multipe_choice_answer, answers,\\\n",
    "                img_id, answer_type, question_id, percent_area_per_catId_all_inst, if_intersect_overlap_sq5, \\\n",
    "                percent_area_per_catId_max_inst\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "coco_val_pkl = './coco_areas_and_intersection/coco_vqa_val2014.json'\n",
    "coco_train_pkl = './coco_areas_and_intersection/coco_vqa_train2014.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "def prep_a_json(dataset, filename, area_thresh, overlap_thresh, all_area_thresh=None):\n",
    "    start = time.time()\n",
    "    abcd = []\n",
    "    file_data = {}\n",
    "    \n",
    "    for i in range(len(dataset)):\n",
    "        ans10, classes_img, nouns_q, nouns_ans, ques_type, multiple, ans, img_id, \\\n",
    "        ans_ty, ques_id,percent_area_per_catId_all_inst,if_intersect_overlap, \\\n",
    "        percent_area_per_catId_max_inst = dataset[i]\n",
    "        \n",
    "        classes_img_set = sorted(list(set(classes_img)))\n",
    "\n",
    "\n",
    "        if len(set(ans10))==1:  #uniform answers\n",
    "            final_target_list = sorted(list(set(classes_img_set) - set(nouns_q) - set(nouns_ans)))\n",
    "            for cat_id_q_a in sorted(list(set(nouns_q)|set(nouns_ans))):\n",
    "                for cat_id in classes_img_set:\n",
    "                    if (cat_id_q_a,cat_id) in if_intersect_overlap.keys():\n",
    "                        if if_intersect_overlap[(cat_id_q_a,cat_id)]> overlap_thresh:\n",
    "                            if cat_id in final_target_list:\n",
    "                                final_target_list.remove(cat_id)\n",
    "\n",
    "    #         for cat_id in classes_img_set:\n",
    "    #             if (percent_area_per_catId_all_inst[cat_id] > area_thresh):\n",
    "    #                 if cat_id in final_target_list:\n",
    "    #                     final_target_list.remove(cat_id)\n",
    "\n",
    "            for cat_id in classes_img_set:\n",
    "                if all_area_thresh is not None:\n",
    "                    if (percent_area_per_catId_max_inst[cat_id] > area_thresh and \\\n",
    "                        percent_area_per_catId_all_inst[cat_id] > all_area_thresh ):\n",
    "                        if cat_id in final_target_list:\n",
    "                            final_target_list.remove(cat_id)\n",
    "                else:\n",
    "                    if (percent_area_per_catId_max_inst[cat_id] > area_thresh):\n",
    "                        if cat_id in final_target_list:\n",
    "                            final_target_list.remove(cat_id)    \n",
    "                    #ipdb.set_trace()\n",
    "\n",
    "            for obj_class in final_target_list :\n",
    "                new_i_id = str(img_id).zfill(12) + '_' + str(obj_class).zfill(12)\n",
    "                abcd.append({\"question_type\": ques_type, \n",
    "                             \"multiple_choice_answer\": multiple, \n",
    "                             \"answers\": ans,\n",
    "                             \"image_id\": new_i_id,\n",
    "                             \"answer_type\": ans_ty,\n",
    "                             \"question_id\": ques_id})\n",
    "                \n",
    "            #if img_id == 427135:\n",
    "                #print(i, ':', dataset[i], final_target_list)\n",
    "                #print(set([ans1[\"answer\"] for ans1 in ans]))\n",
    "                #print([coco_dict[i] for i in final_target_list])\n",
    "            \n",
    "    file_data['annotations'] = abcd \n",
    "    with open(filename, 'w') as outfile_val1:\n",
    "        json.dump(file_data, outfile_val1)\n",
    "    print(time.time()-start)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_a_prep(mode, coco_pkl, area_thresh, overlap_thresh, all_area_thresh=None):  # mode='val2014' or 'train2014'  string\n",
    "    question_path = 'tagged_' + mode + '_questions.json'        ## corresponds to question.json file\n",
    "    answer_path ='tagged_' + mode + '_answers.json'  \n",
    "    \n",
    "    # in case you want to play with thresholds- good idea to store in different folders\n",
    "    #root_dir = os.path.join('mini_datasets_qa', str(area_thresh)+ '_'+str(overlap_thresh))\n",
    "    root_dir = config.iv_a_dir\n",
    "    os.makedirs(root_dir,exist_ok=True)\n",
    "    res_file = 'v2_mscoco_' + mode + '_annotations.json' \n",
    "    \n",
    "    start = time.time()\n",
    "    dataset_mode = VQADataset_custom_ans(coco_pkl, question_path, answer_path, mode)\n",
    "    print(time.time()-start)\n",
    "    prep_a_json(dataset_mode,  os.path.join(root_dir, res_file),area_thresh= area_thresh,\\\n",
    "                overlap_thresh=overlap_thresh, all_area_thresh=all_area_thresh)\n",
    "    # sample check to make sure\n",
    "    print(dataset_mode[0])\n",
    "    with open( os.path.join(root_dir, res_file)) as f:\n",
    "        edited_answers = json.load(f)['annotations']\n",
    "    print(len(edited_answers))\n",
    "    print(edited_answers[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.642129898071289\n",
      "18.825090169906616\n",
      "(['down', 'down', 'at table', 'skateboard', 'down', 'table', 'down', 'down', 'down', 'down'], [5, 15, 41, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 8, 8, 27, 31, 67, 1, 15, 1], [1], [41, 41, 42, 36, 41, 41, 67], 'none of the above', 'down', [{'answer': 'down', 'answer_confidence': 'yes', 'answer_id': 1}, {'answer': 'down', 'answer_confidence': 'yes', 'answer_id': 2}, {'answer': 'at table', 'answer_confidence': 'yes', 'answer_id': 3}, {'answer': 'skateboard', 'answer_confidence': 'yes', 'answer_id': 4}, {'answer': 'down', 'answer_confidence': 'yes', 'answer_id': 5}, {'answer': 'table', 'answer_confidence': 'yes', 'answer_id': 6}, {'answer': 'down', 'answer_confidence': 'yes', 'answer_id': 7}, {'answer': 'down', 'answer_confidence': 'yes', 'answer_id': 8}, {'answer': 'down', 'answer_confidence': 'yes', 'answer_id': 9}, {'answer': 'down', 'answer_confidence': 'yes', 'answer_id': 10}], 262148, 'other', 262148000, {1: 0.099, 5: 0.0, 8: 0.011, 15: 0.077, 27: 0.0, 31: 0.001, 41: 0.004, 67: 0.014}, {(1, 8): 0.046, (1, 15): 0.002, (1, 27): 0.011, (1, 31): 0.018, (1, 41): 0.027, (1, 67): 0.001, (8, 1): 0.384, (8, 27): 0.039, (15, 1): 0.003, (15, 67): 0.21, (27, 1): 0.809, (27, 8): 0.351, (31, 1): 1.0, (41, 1): 0.486, (67, 1): 0.004, (67, 15): 0.981}, {1: 0.043, 5: 0.0, 8: 0.009, 15: 0.075, 27: 0.0, 31: 0.001, 41: 0.004, 67: 0.014})\n",
      "246440\n",
      "{'question_type': 'none of the above', 'multiple_choice_answer': 'down', 'answers': [{'answer': 'down', 'answer_confidence': 'yes', 'answer_id': 1}, {'answer': 'down', 'answer_confidence': 'yes', 'answer_id': 2}, {'answer': 'at table', 'answer_confidence': 'yes', 'answer_id': 3}, {'answer': 'skateboard', 'answer_confidence': 'yes', 'answer_id': 4}, {'answer': 'down', 'answer_confidence': 'yes', 'answer_id': 5}, {'answer': 'table', 'answer_confidence': 'yes', 'answer_id': 6}, {'answer': 'down', 'answer_confidence': 'yes', 'answer_id': 7}, {'answer': 'down', 'answer_confidence': 'yes', 'answer_id': 8}, {'answer': 'down', 'answer_confidence': 'yes', 'answer_id': 9}, {'answer': 'down', 'answer_confidence': 'yes', 'answer_id': 10}], 'image_id': '000000262148_000000000005', 'answer_type': 'other', 'question_id': 262148000}\n"
     ]
    }
   ],
   "source": [
    "final_a_prep('val2014', coco_val_pkl, 0.1, 0.0)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19.05996012687683\n",
      "41.754278898239136\n",
      "(['net', 'net', 'net', 'netting', 'net', 'net', 'mesh', 'net', 'net', 'net'], [37, 1, 40], [58], [], 'what is this', 'net', [{'answer': 'net', 'answer_confidence': 'maybe', 'answer_id': 1}, {'answer': 'net', 'answer_confidence': 'yes', 'answer_id': 2}, {'answer': 'net', 'answer_confidence': 'yes', 'answer_id': 3}, {'answer': 'netting', 'answer_confidence': 'yes', 'answer_id': 4}, {'answer': 'net', 'answer_confidence': 'yes', 'answer_id': 5}, {'answer': 'net', 'answer_confidence': 'yes', 'answer_id': 6}, {'answer': 'mesh', 'answer_confidence': 'maybe', 'answer_id': 7}, {'answer': 'net', 'answer_confidence': 'yes', 'answer_id': 8}, {'answer': 'net', 'answer_confidence': 'yes', 'answer_id': 9}, {'answer': 'net', 'answer_confidence': 'yes', 'answer_id': 10}], 458752, 'other', 458752000, {1: 0.072, 37: 0.0, 40: 0.005}, {(1, 37): 0.011, (1, 40): 0.084, (37, 1): 0.993, (40, 1): 0.991}, {1: 0.072, 37: 0.0, 40: 0.005})\n",
      "514337\n",
      "{'question_type': 'what is this', 'multiple_choice_answer': 'net', 'answers': [{'answer': 'net', 'answer_confidence': 'maybe', 'answer_id': 1}, {'answer': 'net', 'answer_confidence': 'yes', 'answer_id': 2}, {'answer': 'net', 'answer_confidence': 'yes', 'answer_id': 3}, {'answer': 'netting', 'answer_confidence': 'yes', 'answer_id': 4}, {'answer': 'net', 'answer_confidence': 'yes', 'answer_id': 5}, {'answer': 'net', 'answer_confidence': 'yes', 'answer_id': 6}, {'answer': 'mesh', 'answer_confidence': 'maybe', 'answer_id': 7}, {'answer': 'net', 'answer_confidence': 'yes', 'answer_id': 8}, {'answer': 'net', 'answer_confidence': 'yes', 'answer_id': 9}, {'answer': 'net', 'answer_confidence': 'yes', 'answer_id': 10}], 'image_id': '000000458752_000000000001', 'answer_type': 'other', 'question_id': 458752000}\n"
     ]
    }
   ],
   "source": [
    "final_a_prep('train2014',  coco_train_pkl, 0.1,0.0)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}